{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom dataset_segmentationdataset import SegmentationDataset\nimport torchvision\nfrom torch.utils.data import DataLoader\nimport numpy as np","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# checkpoints\n","metadata":{}},{"cell_type":"code","source":"def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state, filename)\n\ndef load_checkpoint(checkpoint, model):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# datasets and loaders\n","metadata":{}},{"cell_type":"code","source":"def create_datasets(masks_dir, slices_dir, augmentations):\n    train_dataset = SegmentationDataset(\n                 slices_dir=slices_dir + \"/train\", \n                 masks_dir=masks_dir + \"/train\",\n                 transforms=augmentations)\n\n    val_dataset = SegmentationDataset(\n                     slices_dir=slices_dir + \"/val\", \n                     masks_dir=masks_dir + \"/val\",\n                     transforms=augmentations)\n\n    test_dataset = SegmentationDataset(\n                     slices_dir=slices_dir + \"/test\", \n                     masks_dir=masks_dir + \"/test\",\n                     transforms=augmentations)\n\n    print(f\"Train size: {len(train_dataset)}\")\n    print(f\"Valid size: {len(val_dataset)}\")\n    print(f\"Test size:  {len(test_dataset)}\")\n        \n    return train_dataset, val_dataset, test_dataset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataloaders(train_dataset, val_dataset, test_dataset, \n                       batch_size=8, pin_memory=True, num_workers=4):\n\n    train_loader = torch.utils.data.DataLoader(\n        dataset=train_dataset, batch_size=batch_size, \n        shuffle=True, pin_memory=pin_memory, num_workers=num_workers)\n\n    val_loader = torch.utils.data.DataLoader(\n        dataset=val_dataset, batch_size=batch_size, \n        shuffle=True, pin_memory=pin_memory, num_workers=num_workers\n    )\n\n    test_loader = torch.utils.data.DataLoader(\n        dataset=test_dataset, batch_size=batch_size, \n        shuffle=False, pin_memory=pin_memory, num_workers=num_workers\n    )\n    return train_loader, val_loader, test_loader","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metrics","metadata":{}},{"cell_type":"code","source":"# count DICE\ndef get_dice(target_mask, predicted_mask):\n    dice_score = (2 * (predicted_mask * target_mask).sum()) / ((predicted_mask + target_mask).sum() + 1e-8)\n\n#     dice = Dice()\n#     metric = dice(predicted_mask, target_mask)\n    return dice_score\n\n\ndef get_mean_dice(test_dataset, predicted_dataset):\n\n    dices = []\n    for idx in range(len(test_dataset)):\n        mask = test_dataset[idx][1]\n        mask_predicted = predicted_dataset[idx]\n        dices.append(get_dice(mask, mask_predicted))\n    \n    mean_dice = np.array(dices).mean()\n    return mean_dice\n\ndef mask_to_image(mask: np.ndarray) -> np.ndarray:\n    if mask.ndim == 2:\n        return np.array((mask * 255).astype(np.uint8))\n    elif mask.ndim == 3:\n        return np.array(\n            (np.argmax(mask, axis=0) * 255 / mask.shape[0]).astype(np.uint8)\n        )\n\n\ndef predict_img(net: nn.Module, img: torch.Tensor, device: str, out_threshold: float = 0.5):\n    net.eval()\n    net.to(device)\n\n    img = img.unsqueeze(0)\n    img = img.to(device=device, dtype=torch.float32)\n\n    with torch.no_grad():\n        output = net(img)\n\n        probs = torch.sigmoid(output)\n        full_mask = probs.cpu().squeeze()\n\n        return full_mask > out_threshold\n    \n    \ndef get_predict(model, image, device):    \n    if type(image) == SegmentationDataset:\n        predicted = []\n        for elem in image:\n            image = elem[0] \n            mask = elem[1]\n            predicted.append(predict_img(model, image, device=device))\n        return predicted\n    \n    predicted_mask = predict_img(model, image, device=device)\n    return predicted_mask\n\n# \ndef check_accuracy(loader, model, device=\"cuda\"):\n    num_correct = 0\n    num_pixels = 0\n    dice_score = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            y = y.to(device).unsqueeze(1) # label does not have chanel\n            \n            # getting probs             \n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n            \n            num_correct += (preds == y).sum()\n            num_pixels += torch.numel(preds)\n            dice_score += (2 * (preds * y).sum()) / (\n                (preds + y).sum() + 1e-8\n            )\n\n    print(\n        f\"Got {num_correct}/{num_pixels} with acc {num_correct/num_pixels*100:.2f}\"\n    )\n    print(f\"Dice score: {dice_score/len(loader)}\")\n    model.train()","metadata":{"_uuid":"b9f3fa1e-d636-42c0-a5aa-40ec1ac7f4ec","_cell_guid":"b7756b4a-d33d-45d2-ac2f-70a4e4d7ae7b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-05-22T11:02:04.620405Z","iopub.execute_input":"2023-05-22T11:02:04.620760Z","iopub.status.idle":"2023-05-22T11:02:04.940272Z","shell.execute_reply.started":"2023-05-22T11:02:04.620732Z","shell.execute_reply":"2023-05-22T11:02:04.938914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Show Results","metadata":{}},{"cell_type":"code","source":"def save_predictions_as_imgs(\n    loader, model, folder=\"saved_images/\", device=\"cuda\"\n):\n    model.eval()\n    for idx, (x, y) in enumerate(loader):\n        x = x.to(device=device)\n        with torch.no_grad():\n            preds = torch.sigmoid(model(x))\n            preds = (preds > 0.5).float()\n        torchvision.utils.save_image(\n            preds, f\"{folder}/pred_{idx}.png\"\n        )\n        torchvision.utils.save_image(y.unsqueeze(1), f\"{folder}{idx}.png\")\n\n    model.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_three(model, img_list, device):    \n    fig, axes = plt.subplots(len(img_list), 3, figsize=(15, 15))\n    for (idx, sample) in enumerate(img_list):\n        image, target_mask = sample\n        predicted_mask = get_predict(image=image, model=model, device=device)\n        dice = get_dice(target_mask, predicted_mask)\n        \n        axes[0].imshow(image.permute(1, 2, 0))\n        axes[0].set_title(\"image\")\n\n        axes[1].imshow(target_mask.squeeze())\n        axes[1].set_title(\"target mask\")\n\n        axes[2].imshow(predicted_mask.squeeze())\n        axes[2].set_title(f\"dice: {dice}\")\n        \n        axes[0].get_xaxis().set_visible(False)\n        axes[0].get_yaxis().set_visible(False)\n        axes[1].get_xaxis().set_visible(False)\n        axes[1].get_yaxis().set_visible(False)\n        axes[2].get_xaxis().set_visible(False)\n        axes[2].get_yaxis().set_visible(False)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]}]}