{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport glob\nimport os\nfrom PIL import Image\nimport numpy as np\n\n\nclass SegmentationDataset(Dataset):\n    def __init__(self,\n                 slices_dir,\n                 masks_dir,\n                 transforms):\n        \n        self.slices_dir = sorted(glob.glob(os.path.join(slices_dir, \"*.png\")))      \n        self.masks_dir = sorted(glob.glob(os.path.join(masks_dir, \"*.png\")))      \n        self.transforms = transforms\n\n        assert len(self.slices_dir) == len(self.masks_dir)\n\n        \n\n    def __getitem__(self, idx):\n        image = np.array(Image.open(self.slices_dir[idx]))\n        mask = np.array(Image.open(self.masks_dir[idx]))\n \n        mask[mask == 255.0] = 1.0\n\n        if self.transforms is not None:\n            augmentations = self.transforms(image=image, mask=mask)\n            image = augmentations[\"image\"]\n            mask = augmentations[\"mask\"]\n            mask = torch.unsqueeze(mask, 0)\n            mask = mask.type(torch.uint8)\n\n        return image, mask\n\n    def __len__(self):\n        return len(self.slices_dir)","metadata":{"_uuid":"510f4d6b-a613-4c81-8339-74f3da6e5d65","_cell_guid":"6b155651-acd2-4fd1-9ae5-9c33e02ebeda","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}